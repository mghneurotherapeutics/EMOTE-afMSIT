{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Assemble Behavior\n",
    "Using the TRANSFORM-DBS MSIT data collected from healthy controls. Here we are just checking over participants to exclude individuals with many missing trials or error responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "root_dir = '/space/sophia/2/users/DARPA-Behavior/msit/csv'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "observed = 0.90    # 90% or more of possible data must be present\n",
    "accuracy = 0.90    # 90% accuracy or higher\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "csv_files = sorted([f for f in os.listdir(root_dir) if f.startswith('hc') and f.endswith('mri-1')])\n",
    "sessid = open('scripts/fsfast/sessid', 'w')\n",
    "\n",
    "for f in csv_files:\n",
    "    \n",
    "    ## Get subject name.\n",
    "    subject = f.split('_')[0]\n",
    "    \n",
    "    ## Load CSV.\n",
    "    df = read_csv(os.path.join(root_dir,f))\n",
    "    df = df[df.Condition != 0].reset_index(drop=True)   # Drop rest trials.\n",
    "    \n",
    "    ## Assess quality.\n",
    "    if (df.ResponseAccuracy != 99).mean() < observed: continue\n",
    "    else: df = df[df.ResponseAccuracy != 99].reset_index(drop=True)\n",
    "    \n",
    "    if df.ResponseAccuracy.mean() < accuracy: continue\n",
    "    else: sessid.write('%s\\n' %subject)\n",
    "    \n",
    "## Save.\n",
    "sessid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Construct Regressors\n",
    "Boxcars made following Grinband et al. (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from pandas import read_csv\n",
    "from scipy.special import gammaln\n",
    "root_dir = '/space/sophia/2/users/DARPA-Behavior/msit/csv'\n",
    "mri_dir = '/space/lilli/4/users/DARPA-MSIT'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define contrasts.\n",
    "conditions = ['Neu','Int']\n",
    "n_conditions = len(conditions)\n",
    "\n",
    "## Timing information.\n",
    "n_acq = 228\n",
    "tr = 1.75\n",
    "sfreq = 1e2\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define useful functions.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "def spm_hrf(RT, P=None, fMRI_T=16):\n",
    "    p = np.array([6, 16, 1, 1, 6, 0, 32], dtype=float)\n",
    "    if P is not None:\n",
    "        p[0:len(P)] = P\n",
    "\n",
    "    _spm_Gpdf = lambda x, h, l: np.exp(h * np.log(l) + (h - 1) * np.log(x) - (l * x) - gammaln(h))\n",
    "    # modelled hemodynamic response function - {mixture of Gammas}\n",
    "    dt = RT / float(fMRI_T)\n",
    "    u = np.arange(0, int(p[6] / dt + 1)) - p[5] / dt\n",
    "    with np.errstate(divide='ignore'):  # Known division-by-zero\n",
    "        hrf = _spm_Gpdf(u, p[0] / p[2], dt / p[2]) - _spm_Gpdf(u, p[1] / p[3],\n",
    "                                                               dt / p[3]) / p[4]\n",
    "    idx = np.arange(0, int((p[6] / RT) + 1)) * fMRI_T\n",
    "    hrf = hrf[idx]\n",
    "    hrf = hrf / np.sum(hrf)\n",
    "    return hrf\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "subjects = np.loadtxt('scripts/fsfast/sessid.manual', dtype='str')\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    print subject,\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Initialize regressors.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "    \n",
    "    ## Setup timing information.\n",
    "    total_time = n_acq * tr\n",
    "    times = np.arange(0, total_time+1./sfreq, 1./sfreq)\n",
    "    n_times = times.shape[0]\n",
    "\n",
    "    ## Initialize boxcars.\n",
    "    neural_signal = np.zeros((n_conditions,n_times))\n",
    "    \n",
    "    ## Load behavior information.\n",
    "    df = read_csv(os.path.join(root_dir, '%s_msit_mri-1' %subject))\n",
    "    df = df[df.Condition != 0]            # Drop rest trials.\n",
    "    df = df[df.ResponseAccuracy != 99]    # Drop missing trials.\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Generate boxcars.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "    \n",
    "    for n in range(n_conditions):\n",
    "        \n",
    "        ## Extract onsets/offsets.\n",
    "        onsets  = df.loc[df.Condition==n+1, 'StimOnset'].as_matrix()\n",
    "        offsets = df.loc[df.Condition==n+1, 'ResponseOnset'].as_matrix()\n",
    "        \n",
    "        ## Round onsets/offsets.\n",
    "        onsets  = onsets.round(np.log10(sfreq).astype(int))\n",
    "        offsets = offsets.round(np.log10(sfreq).astype(int))\n",
    "        \n",
    "        ## Iteratively generate boxcars.\n",
    "        for onset, offset in zip(onsets,offsets): \n",
    "            mask = (times >= onset) & (times <= offset)\n",
    "            neural_signal[n,mask] = 1\n",
    "\n",
    "    ## Perform convolution.\n",
    "    hrf = spm_hrf(1./sfreq)\n",
    "    bold_signal = np.apply_along_axis(np.convolve, 1, neural_signal, v=hrf)\n",
    "    bold_signal = bold_signal[:,:neural_signal.shape[-1]] # Set back to original length.\n",
    "    \n",
    "    ## Downsample to start of TR.\n",
    "    tr_onsets = np.insert( np.cumsum( np.ones(n_acq-1)*tr ), 0, 0 )\n",
    "    ds = np.in1d(times, tr_onsets)\n",
    "    if not ds.sum() == n_acq: raise ValueError('Oh noes!')\n",
    "    bold_signal = bold_signal[:,ds]\n",
    "    \n",
    "    ## Normalize regressors. [See Calhoun et al. (2004)]\n",
    "    ## First we normalize [Intercept, DDB, Valence] such that the sum\n",
    "    ## of their timeseries squared is equal to 1.\n",
    "    sums = np.power(bold_signal,2).sum(axis=1)\n",
    "    bold_signal = (bold_signal.T / np.sqrt(sums)).T\n",
    "    \n",
    "    ## Save task regressors.\n",
    "    for arr, label in zip(bold_signal, conditions):\n",
    "\n",
    "        f = '%s/%s/msit_001/001/afMSIT.%s.par' %(mri_dir,subject,label)\n",
    "        try: np.savetxt(f, arr[:,np.newaxis], fmt='%s')\n",
    "        except IOError: pass\n",
    "    \n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Construct Timepoint Censors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from scipy.signal import detrend\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "mri_dir = '/space/lilli/4/users/DARPA-MSIT'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Timing information.\n",
    "n_acq = 228\n",
    "tr = 1.75\n",
    "\n",
    "## Scrubbing parameters.\n",
    "thresholds = [0.0, 0.5, 1.0]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define TR onsets.\n",
    "tr_onsets = np.insert( np.cumsum( np.ones(n_acq - 1) * tr ), 0, 0 )\n",
    "\n",
    "## Get subjects list.\n",
    "subjects = np.loadtxt('scripts/fsfast/sessid', dtype='str')\n",
    "info = open('fmri/nuisance_info.csv','w')\n",
    "info.write('Subject,n_mc,FD=0.0,FD=0.5,FD=1.0\\n')\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    info.write('%s,' %subject)\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Compute framewise displacement.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Read motion data.\n",
    "    mc = os.path.join(mri_dir, subject, 'msit_001', '001', 'fmcpr.mcdat')\n",
    "    try: mc = np.loadtxt(mc)[:,1:7]\n",
    "    except IOError: \n",
    "        print 'Drop %s.' %subject\n",
    "        continue\n",
    "\n",
    "    ## Invert angular displacement.\n",
    "    fd = mc.copy()\n",
    "    fd[:,:3] = np.deg2rad(fd[:,:3]) \n",
    "    fd[:,:3] *= 50\n",
    "\n",
    "    ## Compute framewise displacement (See Power 2012, 2014).\n",
    "    fd = np.insert( np.abs( np.diff(fd, axis=0) ).sum(axis=1), 0, 0 )\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Compute motion regressors.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Remove trends.\n",
    "    mc = detrend(mc, axis=0, type='constant')\n",
    "    mc = detrend(mc, axis=0, type='linear')\n",
    "    \n",
    "    ## Perform PCA.\n",
    "    pca = PCA(n_components=6)\n",
    "    mc = pca.fit_transform(mc)\n",
    "    \n",
    "    ## Take only the number of components explaining 90% of the variance.\n",
    "    varexp = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(varexp >= 0.9) + 1\n",
    "    mc = mc[:,:n_components]\n",
    "    \n",
    "    ## Save motion regressor.\n",
    "    f = '%s/%s/msit_001/001/afMSIT.mc.par' %(mri_dir,subject)\n",
    "    np.savetxt(f, mc, fmt='%s')\n",
    "    info.write('%s,' %n_components)\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Write scrubbers.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        ## Find threshold violations.\n",
    "        if not threshold: ix, = np.where(fd >= np.inf)\n",
    "        else: ix, = np.where(fd >= threshold)\n",
    "                \n",
    "        ## Save.\n",
    "        info.write('%s,' %len(ix))\n",
    "        f = '%s/%s/msit_001/001/afMSIT.censor.%s.par' %(mri_dir,subject,threshold)\n",
    "        if len(ix): np.savetxt(f, tr_onsets[ix,np.newaxis], fmt='%s')\n",
    "\n",
    "    info.write('\\n')\n",
    "\n",
    "info.close()\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Compute Group Statistics\n",
    "\n",
    "Following the formulas detailed in Pernet (2014): Misconceptions in the use of the General Linear Model applied to functional MRI: a tutorial for junior neuro-imagers\n",
    "\n",
    "## Step 4a: Compute Beta Constants (Mean Signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "mri_dir = '/space/lilli/4/users/DARPA-MSIT'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "subjects = np.loadtxt('scripts/fsfast/sessid.manual', dtype='str')\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    print subject,\n",
    "    \n",
    "    for hemi in ['lh','rh']:\n",
    "        \n",
    "        ## Load data.\n",
    "        f = os.path.join(mri_dir, subject, 'msit_001', '001', 'fmcpr.sm6.fsaverage.%s.b0dc.nii.gz' %hemi)\n",
    "        obj = nib.load(f)\n",
    "        \n",
    "        ## Extract data and average over acquisitions.\n",
    "        data = obj.get_data()\n",
    "        data = np.apply_over_axes(np.mean, data, -1)\n",
    "        \n",
    "        ## Save.\n",
    "        f = os.path.join(mri_dir, subject, 'msit_001', 'afMSIT.6.0.5.%s' %hemi, 'betaconstant.nii.gz')\n",
    "        obj = nib.Nifti1Image(data, obj.affine)\n",
    "        nib.save(obj, f)\n",
    "        \n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4b: Compute Percent Signal Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "mri_dir = '/space/lilli/4/users/DARPA-MSIT'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "subjects = np.loadtxt('scripts/fsfast/sessid.manual', dtype='str')\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    print subject,\n",
    "    \n",
    "    for hemi in ['lh','rh']:\n",
    "        \n",
    "        subj_dir = os.path.join(mri_dir, subject, 'msit_001', 'afMSIT.6.0.5.%s' %hemi)\n",
    "        \n",
    "        ## Load constants.\n",
    "        design_matrix = np.loadtxt(os.path.join(subj_dir, 'X.dat'))\n",
    "        mean_signal = nib.load(os.path.join(subj_dir, 'betaconstant.nii.gz')).get_data()\n",
    "        \n",
    "        ## Iteratively compute PSC across conditions.\n",
    "        for n, con in enumerate(['Neu','Int']):\n",
    "            \n",
    "            ## Load contrast.\n",
    "            ces = nib.load(os.path.join(subj_dir, 'afMSIT.%s.par' %con, 'ces.nii.gz'))\n",
    "            affine = ces.affine\n",
    "            ces = ces.get_data()\n",
    "            \n",
    "            ## Compute PSC.\n",
    "            sf = design_matrix.max(axis=0)[n]\n",
    "            psc = ces * sf / mean_signal * 100.\n",
    "            \n",
    "            ## Save.\n",
    "            psc = nib.Nifti1Image(psc, affine)\n",
    "            nib.save(psc, os.path.join(subj_dir, 'afMSIT.%s.par' %con, 'psc.nii.gz'))\n",
    "            \n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4c: Compute Group Contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from statsmodels.api import WLS\n",
    "mri_dir = '/space/lilli/4/users/DARPA-MSIT'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "subjects = np.loadtxt('scripts/fsfast/sessid.manual', dtype='str')\n",
    "\n",
    "for hemi in ['lh','rh']:\n",
    "    \n",
    "    print 'Starting analysis of %s.' %hemi\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Iteratively load data.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    print 'Loading subjects data.',\n",
    "    \n",
    "    psc, var = [], []\n",
    "    for subject in subjects:\n",
    "        \n",
    "        ## Define subject directory.\n",
    "        subj_dir = os.path.join(mri_dir, subject, 'msit_001', 'afMSIT.6.0.5.%s' %hemi)\n",
    "        \n",
    "        for con in ['Neu','Int']:\n",
    "            \n",
    "            ## Load percent signal change.\n",
    "            f = os.path.join(subj_dir, 'afMSIT.%s.par' %con, 'psc.nii.gz')\n",
    "            psc.append( nib.load(f).get_data() )\n",
    "            \n",
    "            ## Load contrast variance.\n",
    "            f = os.path.join(subj_dir, 'afMSIT.%s.par' %con, 'cesvar.nii.gz')\n",
    "            obj = nib.load(f)\n",
    "            var.append( obj.get_data() )\n",
    "    \n",
    "    ## Concatenate contrasts.\n",
    "    psc = np.concatenate(psc, axis=-1).squeeze()\n",
    "    var = np.concatenate(var, axis=-1).squeeze()\n",
    "    affine = obj.affine\n",
    "    print 'Finished.'\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Iteratively perform statistics.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    print 'Compute contrast statistics.',\n",
    "    \n",
    "    ## Preallocate arrays.\n",
    "    n_vert, n_cons = psc.shape\n",
    "    Fvals, pvals = np.zeros((n_vert, 3)), np.zeros((n_vert, 3))\n",
    "\n",
    "    ## Generate design matrix.\n",
    "    X = np.zeros((n_cons,2))\n",
    "    X[::2,0] = 1               # Neutral contrasts.\n",
    "    X[1::2,1] = 1              # Interference contrasts.\n",
    "\n",
    "    ## Generate weights.\n",
    "    W = 1. / np.power(var, 2)\n",
    "\n",
    "    ## Iterate over vertices.\n",
    "    contrasts = [[1,0],[0,1],[-1,1]]\n",
    "    for n in range(n_vert):\n",
    "\n",
    "        ## Check if no data available.\n",
    "        if np.any(np.isinf(W[n])): continue\n",
    "\n",
    "        ## Fit model.\n",
    "        model = WLS(psc[n], X, W[n]).fit()        \n",
    "        \n",
    "        ## Determine signs.\n",
    "        signs = np.zeros(3)\n",
    "        signs[:2] = np.sign(model.params)\n",
    "        signs[-1] = np.sign(np.diff(model.params))\n",
    "        \n",
    "        ## Compute contrasts.\n",
    "        for m, c in enumerate(contrasts):\n",
    "\n",
    "            contrast = model.f_test(c)\n",
    "            Fvals[n,m] = contrast.fvalue.max() * signs[m]\n",
    "            pvals[n,m] = contrast.pvalue.max() * signs[m]\n",
    "\n",
    "    ## Transform p-values.\n",
    "    pvals = -np.log10(np.abs(pvals)) * np.sign(pvals)\n",
    "    print 'Finished.'\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Save results.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    print 'Saving results.',\n",
    "    \n",
    "    for n, contrast in enumerate(['neu','int','diff']):\n",
    "        \n",
    "        ## Make out directory.\n",
    "        out_dir = 'fmri/afMSIT.%s.%s' %(contrast,hemi)\n",
    "        if not os.path.isdir(out_dir): os.makedirs(out_dir)\n",
    "        \n",
    "        ## Save F-statistics.\n",
    "        F = Fvals[:,n]\n",
    "        for _ in range(2): F = F[:,np.newaxis]\n",
    "        obj = nib.Nifti1Image(F, affine)\n",
    "        nib.save(obj, os.path.join(out_dir,'F.mgz'))\n",
    "        \n",
    "        ## Save p-values.\n",
    "        p = pvals[:,n]\n",
    "        for _ in range(2): p = p[:,np.newaxis]\n",
    "        obj = nib.Nifti1Image(p, affine)\n",
    "        nib.save(obj, os.path.join(out_dir,'sig.mgz'))\n",
    "            \n",
    "    print 'Finished.'\n",
    "    \n",
    "print 'Done.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
