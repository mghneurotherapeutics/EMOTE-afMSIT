{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures (Original Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSIT Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from surfer import Brain\n",
    "%matplotlib qt4\n",
    "\n",
    "fs_dir = '/autofs/space/sophia_002/users/EMOTE-DBS/freesurfs'\n",
    "subj_dir = os.environ[\"SUBJECTS_DIR\"]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Surface parameters.\n",
    "subject = \"fscopy\"\n",
    "surf = \"inflated\"\n",
    "hemi = 'lh'\n",
    "\n",
    "## I/O parameters.\n",
    "overlay = os.path.join(fs_dir, subject, 'label', 'april2016', 'darpa_msit_overlay-lh.mgz')\n",
    "color = '#AFFF94'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Make Figure.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "labels = ['dacc-lh', 'dmpfc-lh', 'dlpfc_1-lh', 'dlpfc_2-lh', 'dlpfc_3-lh', \n",
    "          'dlpfc_4-lh', 'dlpfc_5-lh', 'dlpfc_6-lh', 'pcc-lh', 'racc-lh']\n",
    "\n",
    "brain = Brain(subject, hemi, surf, background='white')\n",
    "for label in labels:\n",
    "    label = os.path.join(fs_dir, subject, 'label', 'april2016', '%s.label' %label)\n",
    "    brain.add_label(label, color=color, alpha=1, borders=3)\n",
    "brain.add_overlay(overlay, min=1.301, max=5, sign='pos', name='msit')\n",
    "brain.overlays['msit'].pos_bar.visible = False\n",
    "\n",
    "## Lateral view.\n",
    "brain.show_view(dict(azimuth=150, roll=90), distance=350)\n",
    "brain.save_image('plots/manuscript/fig1/msit_overlay_lateral.png')\n",
    "\n",
    "## Medial view.\n",
    "brain.show_view('medial', distance=425)\n",
    "brain.save_image('plots/manuscript/fig1/msit_overlay_medial.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from surfer import Brain\n",
    "%matplotlib qt4\n",
    "\n",
    "fs_dir = '/media/SZORO/arc-fir/recons/'\n",
    "\n",
    "brain = Brain('fscopy', 'lh', 'pial', subjects_dir=fs_dir)\n",
    "# brain.add_label('/media/SZORO/arc-fir/recons/fscopy/label/laus125/superiorfrontal_4-lh.label')\n",
    "# brain.add_label('/media/SZORO/arc-fir/recons/fscopy/label/laus125/caudalmiddlefrontal_1-lh.label')\n",
    "# brain.show_view('medial')\n",
    "brain.add_label('/media/SZORO/EMOTE-DBS/freesurfs/fscopy/label/april2016/dlpfc_2-lh.label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Average Topoplots (Time-Domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from mne import EpochsArray, combine_evoked, grand_average, read_epochs, set_log_level\n",
    "from mne.channels import read_montage\n",
    "from mne.filter import low_pass_filter\n",
    "set_log_level(verbose=False)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "subjects = ['BRTU','CHDR','CRDA','JADE','JASE','M5','MEWA','S2']\n",
    "analysis = 'resp'\n",
    "task = 'msit'\n",
    "h_freq = 50\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "montage = read_montage('standard_1020')\n",
    "\n",
    "evokeds = []\n",
    "\n",
    "for subject in subjects:\n",
    "\n",
    "    ## Load epochs.\n",
    "    epochs = read_epochs('ave/%s_%s_%s_%s-epo.fif' %(subject,task,h_freq,analysis))\n",
    "\n",
    "    ## Update channel names according to montage.\n",
    "    ch_map = dict()\n",
    "    for ch in epochs.ch_names:\n",
    "        ix = [m.lower() for m in montage.ch_names].index(ch.lower())\n",
    "        ch_map[ch] = montage.ch_names[ix]\n",
    "    epochs.rename_channels(ch_map)\n",
    "\n",
    "    ## Set montage.\n",
    "    epochs.set_montage(montage)\n",
    "\n",
    "    ## Lowpass filter. Reassemble.\n",
    "    data = epochs.get_data()        \n",
    "    data = low_pass_filter(data, epochs.info['sfreq'], 15., filter_length='2s', n_jobs=3,)\n",
    "    epochs = EpochsArray(data, epochs.info, epochs.events, epochs.tmin, epochs.event_id, proj=False)\n",
    "\n",
    "    ## Compute evoked.\n",
    "    evokeds.append( epochs.average() )\n",
    "\n",
    "## Compute grand average.\n",
    "evokeds = grand_average(evokeds)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "if analysis == 'stim': \n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = plt.subplot2grid((1,1),(0,0))\n",
    "    evokeds.plot_topomap(times = 0.52, cmap='spectral', colorbar=False, average=0.05, axes=ax)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = plt.subplot2grid((1,1),(0,0))\n",
    "    evokeds.plot_topomap(times = 0.52, cmap='spectral', colorbar=True, average=0.05, axes=ax)   \n",
    "\n",
    "elif analysis == 'resp':\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = plt.subplot2grid((1,1),(0,0))\n",
    "    evokeds.plot_topomap(times = -0.7, cmap='spectral', colorbar=False, average=0.05, axes=ax)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    ax = plt.subplot2grid((1,1),(0,0))\n",
    "    evokeds.plot_topomap(times = -0.7, cmap='spectral', colorbar=True, average=0.05, axes=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dACC Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## File parameters.\n",
    "model_name = 'revised'\n",
    "space = 'source'\n",
    "label = 'dacc-lh'\n",
    "freq = 15\n",
    "\n",
    "## Plotting parameters.\n",
    "contrasts = ['Interference','DBS']\n",
    "palettes = [ ['#7b3294','#008837'], ['#0571b0','#ca0020'] ]\n",
    "annotations = [ ['Control', 'Interference'], ['DBS OFF','DBS ON'] ]\n",
    "y1, y2 = -0.2, 0.3\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Intialize figure.\n",
    "fig, axes = plt.subplots(2,2,figsize=(12,8),sharey=True)\n",
    "info = read_csv(os.path.join(space, 'afMSIT_%s_info.csv' %space))\n",
    "\n",
    "for n, contrast, colors, legends in zip(range(2), contrasts, palettes, annotations):\n",
    "    \n",
    "    for m, analysis in enumerate(['stim', 'resp']):\n",
    "\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Load data.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        ## Load source data.\n",
    "        npz = np.load(os.path.join(space, 'afMSIT_%s_%s_%s_%s.npz' %(space,analysis,label,freq)))\n",
    "        data = npz['data']\n",
    "        times = npz['times']\n",
    "\n",
    "        ## Load cluster results.\n",
    "        f = os.path.join(space, 'results', '%s_%s_timedomain_results.csv' %(model_name, analysis))\n",
    "        clusters = read_csv(f)\n",
    "        \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Plotting.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        for i, color, legend in zip(range(2),colors,legends):\n",
    "\n",
    "            ix, = np.where(info[contrast]==i)\n",
    "            mu = data[ix].mean(axis=0)\n",
    "            se = data[ix].std(axis=0) / np.sqrt(len(ix))\n",
    "            axes[n,m].plot(times, mu, linewidth=3, color=color, label=legend)\n",
    "            axes[n,m].fill_between(times, mu-se, mu+se, color=color, alpha=0.2)\n",
    "\n",
    "        ## Plot significant clusters.\n",
    "        axes[n,m].set_ylim(-0.2,0.2)\n",
    "        for ix in np.where((clusters.Label==label)&(clusters.Freq==freq)&\n",
    "                           (clusters.Contrast==contrast)&(clusters.FDR<0.05))[0]:\n",
    "            tmin, tmax = clusters.loc[ix,'Tmin'], clusters.loc[ix,'Tmax']\n",
    "            axes[n,m].fill_between(np.linspace(tmin,tmax,1e3), y1, y2, color='k', alpha=0.2)    \n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Add flourishes.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for n in range(2):\n",
    "    \n",
    "    for m in range(2):\n",
    "        \n",
    "        ## Stimulus-locked edits.\n",
    "        if not m:\n",
    "            \n",
    "            ## Fix axes.\n",
    "            xticks = np.array([0.0, 0.4, 0.9, 1.4])\n",
    "            axes[n,m].set(xticks=xticks, xticklabels=xticks - 0.4, \n",
    "                          xlim=(-0.25,1.5), ylim=(y1,y2))\n",
    "\n",
    "            \n",
    "            ## Add markers.\n",
    "            for x,s in zip([0, 0.4, 1.127],['IAPS','MSIT','Resp']): \n",
    "                axes[n,m].text(x+0.02,y1+np.abs(y1*0.05),s,fontsize=22)\n",
    "                axes[n,m].vlines(x,y1,y2,linestyle='--',alpha=0.3)\n",
    "                \n",
    "        ## Response-locked edits.\n",
    "        else:\n",
    "            \n",
    "            ## Fix axes.\n",
    "            xticks = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n",
    "            axes[n,m].set(xticks=xticks, xlim=(-1.0, 1.0))\n",
    "                        \n",
    "            ## Add markers\n",
    "            axes[n,m].text(0.02,y1+np.abs(y1*0.05),'Resp',fontsize=22)\n",
    "            axes[n,m].vlines(0.0,y1,y2,linestyle='--',alpha=0.3)\n",
    "        \n",
    "            ## Add legends above plot.\n",
    "            axes[n,m].legend(loc=1, handlelength=1.2, handletextpad=0.5, \n",
    "                             labelspacing=0.1, borderpad=0)\n",
    "        \n",
    "        ## Add y-labels.\n",
    "        if n: axes[n,m].set_xlabel('Time (s)')\n",
    "            \n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(top=0.97, left = 0.08, right = 0.98, \n",
    "                    bottom=0.1, hspace=0.35, wspace=0.1)\n",
    "plt.savefig('plots/manuscript/fig2/dacc_erp.png')\n",
    "plt.savefig('plots/manuscript/fig2/dacc_erp.svg')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant ERP Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load data.\n",
    "f = 'source/results/revised_stim_timedomain_results.csv'\n",
    "df = read_csv(f)\n",
    "\n",
    "## Limit data.\n",
    "df = df[df.FDR<0.05].reset_index(drop=True)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,12))\n",
    "\n",
    "labels = ['racc-lh', 'dacc-lh', 'pcc-lh', 'dmpfc-lh', 'dlpfc_1-lh', 'dlpfc_2-lh', \n",
    "          'dlpfc_3-lh', 'dlpfc_4-lh', 'dlpfc_5-lh', 'dlpfc_6-lh', \n",
    "          'racc-rh', 'dacc-rh', 'pcc-rh', 'dmpfc-rh', 'dlpfc_1-rh', 'dlpfc_2-rh', \n",
    "          'dlpfc_3-rh', 'dlpfc_4-rh', 'dlpfc_5-rh', 'dlpfc_6-rh']\n",
    "\n",
    "for n in range(len(df)):\n",
    "    \n",
    "    if df.loc[n,'Contrast'] == 'Interference': color = '#008837'\n",
    "    elif df.loc[n,'Contrast'] == 'nsArousal': color = '#e6550d'\n",
    "    else: continue\n",
    "        \n",
    "    y = labels[::-1].index(df.loc[n,'Label'])\n",
    "    ax.fill_between(df.loc[n,['Tmin','Tmax']].astype(float), y+0.05, y+0.95, color=color, alpha=0.8)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Add flourishes.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Add legend.\n",
    "for label, color in zip(['Interference','Arousal'],['#008837','#e6550d']): \n",
    "    ax.plot([],[],lw=10,color=color,label=label,alpha=0.7)\n",
    "ax.legend(bbox_to_anchor=(0.7,1.1), handlelength=1.25, borderaxespad=0)\n",
    "    \n",
    "## Add timing details.\n",
    "y1, y2 = 0, len(labels)\n",
    "for x,s in zip([0, 0.4, 1.127],['IAPS','MSIT','Resp']): \n",
    "    ax.text(x+0.02,0.25,s,fontsize=20)\n",
    "    ax.vlines(x, y1, y2, linewidth=2.5, linestyle='--',alpha=0.2)    \n",
    "\n",
    "## Fix x-axis.\n",
    "xticks = np.array([0.0, 0.4, 0.9, 1.4])\n",
    "ax.set(xticks=xticks, xticklabels=xticks-0.4, xlim=(-0.25,1.5),xlabel='Time (s)')\n",
    "\n",
    "## Fix y-axis.\n",
    "labels = ['rACC', 'dACC', 'mCC', 'SFG', 'pMFG 1', 'pMFG 2', 'aMFG 1', 'aMFG 2', 'aIFG', 'pIFG'] * 2\n",
    "ax.set(yticks=np.arange(len(labels))+0.5, yticklabels=labels[::-1], ylim=(0,len(labels)))\n",
    "\n",
    "## Add dendrograms.\n",
    "def dendrogram(ax, x, y1, y2, text):\n",
    "    \n",
    "    ## Parameters\n",
    "    lw = 2.0\n",
    "    alpha = 0.2\n",
    "    \n",
    "    ## Drawing\n",
    "    ax.annotate('', (x, y1), xycoords='axes fraction', xytext=(x,y2), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate('', (x*1.02,y1), xycoords='axes fraction', xytext=(-1e-3,y1), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate('', (x*1.02,y2), xycoords='axes fraction', xytext=(-1e-3,y2), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate(text, (0,0), xycoords='axes fraction', xytext=(x*1.4, np.mean([y1,y2])), \n",
    "                rotation=90, va='center')\n",
    "\n",
    "dendrogram(ax, -0.38, 0, 0.495, 'Right Hemisphere')\n",
    "dendrogram(ax, -0.38, 0.505, 1, 'Left Hemisphere')\n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(left=0.35, right=0.975, top=0.925, bottom=0.075)\n",
    "plt.savefig('plots/manuscript/fig2/all_erps.png', dpi=180)\n",
    "plt.savefig('plots/manuscript/fig2/all_erps.svg', dpi=180)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Mass Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv, concat\n",
    "\n",
    "combined = []\n",
    "for analysis in ['stim', 'resp']:\n",
    "    \n",
    "    ## Load info.\n",
    "    df = read_csv('source/results/revised_%s_frequency_results.csv' %analysis)\n",
    "    df = df[(df.Contrast=='DBS') & (df.Freq=='theta') & (df.FDR<0.05)]\n",
    "    \n",
    "    ## Define times.\n",
    "    if analysis == 'stim': times = np.arange(0,1.5,1/1450.)\n",
    "    elif analysis == 'resp': times = np.arange(-1,1,1/1450.)\n",
    "\n",
    "    ## Make events mask.\n",
    "    if analysis == 'stim': mask_eve = (times > 0.4) & (times < 1.127)\n",
    "    elif analysis == 'resp': mask_eve = (times < 0)\n",
    "    \n",
    "    ## Iteratively compute percentage within window.\n",
    "    percentages = []\n",
    "    for _, row in df.iterrows():    \n",
    "    \n",
    "        ## Make significance mask.\n",
    "        mask_sig = np.zeros_like(times)\n",
    "        mask_sig += (times > row.Tmin) & (times < row.Tmax)\n",
    "        mask_sig = mask_sig.astype(bool)\n",
    "\n",
    "        ## Compute overlap.\n",
    "        overlap = np.logical_and(mask_sig, mask_eve).sum() / mask_sig.sum().astype(float)\n",
    "        percentages.append( overlap * 1e2 )\n",
    "        \n",
    "    print('%s: %0.3f' %(analysis, np.mean(percentages)))\n",
    "    \n",
    "    combined.append(df)\n",
    "    \n",
    "## Compute hemisphere dominance.\n",
    "combined = concat(combined)\n",
    "combined['hemi'] = ['lh' if label.endswith('lh') else 'rh' for label in combined.Label]\n",
    "gb = combined.groupby('hemi').Tdiff.sum()\n",
    "print(gb['lh'] / gb.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Average Topoplots (Power Domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from mne import concatenate_epochs, read_epochs, set_log_level\n",
    "from mne.channels import read_montage\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.viz.topomap import _prepare_topo_plot\n",
    "set_log_level(verbose=False)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "subjects = ['BRTU','CHDR','CRDA','JADE','JASE','M5','MEWA','S2']\n",
    "analysis = 'stim'\n",
    "task = 'msit'\n",
    "h_freq = 50\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "montage = read_montage('standard_1020')\n",
    "\n",
    "for analysis in ['stim','resp']:\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Load data.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    print 'Beginning processing for %s.' %analysis,\n",
    "    data = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "\n",
    "        ## Load epochs.\n",
    "        epochs = read_epochs('ave/%s_%s_%s_%s-epo.fif' %(subject,task,h_freq,analysis))\n",
    "\n",
    "        ## Update channel names according to montage.\n",
    "        ch_map = dict()\n",
    "        for ch in epochs.ch_names:\n",
    "            ix = [m.lower() for m in montage.ch_names].index(ch.lower())\n",
    "            ch_map[ch] = montage.ch_names[ix]\n",
    "        epochs.rename_channels(ch_map)\n",
    "\n",
    "        ## Set montage.\n",
    "        epochs.set_montage(montage)\n",
    "\n",
    "        ## Subtract evoked.\n",
    "        epochs = epochs.subtract_evoked()\n",
    "        \n",
    "        ## Compute evoked.\n",
    "        epochs.info['projs'] = []\n",
    "        data.append( epochs )\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Concatenate epochs.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Identify list of common channels.\n",
    "    channels = np.concatenate([epochs.ch_names for epochs in data])\n",
    "    channels = [ch for ch, count in zip(*np.unique(channels, return_counts=True)) \n",
    "                if count==len(subjects)]\n",
    "\n",
    "    ## Iteratively drop non-common channels.\n",
    "    for n in range(len(subjects)):\n",
    "\n",
    "        epochs = data[n]\n",
    "        epochs = epochs.drop_channels([ch for ch in epochs.ch_names if ch not in channels])\n",
    "        data[n] = epochs\n",
    "\n",
    "    data = concatenate_epochs(data)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### TFR.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Compute TFR. \n",
    "    freqs = np.arange(4,8+1e-6,2)\n",
    "    n_cycles = 3\n",
    "    tfr = tfr_morlet(data, freqs, n_cycles, return_itc=False, verbose=False)\n",
    "    \n",
    "    ## Compute baseline.\n",
    "    if analysis == 'stim':\n",
    "        mask = (tfr.times >= -0.5) & (tfr.times <= -0.1)\n",
    "        baseline = np.median(tfr.data[:,:,mask], axis=-1)\n",
    "        \n",
    "    ## Baseline correct.\n",
    "    data = tfr.data.copy().T / baseline.T\n",
    "    data = 10 * np.log10(data.T)\n",
    "    \n",
    "    ## Average.\n",
    "    data = np.apply_along_axis(np.median, 1, data).squeeze()\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Plotting.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    _, pos, _, _, _ = _prepare_topo_plot(tfr, 'eeg', None)\n",
    "    np.savez_compressed('plots/manuscript/fig3/%s' %analysis, data=data, times=tfr.times, pos=pos)\n",
    "    \n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mne.viz import plot_topomap\n",
    "%matplotlib inline\n",
    "\n",
    "for analysis, v in zip(['stim', 'resp'], [3.5, 4.5]):\n",
    "\n",
    "    ## Load data.\n",
    "    npz = np.load('plots/manuscript/fig3/%s.npz' %analysis)\n",
    "    data = npz['data']\n",
    "    times = npz['times']\n",
    "    pos = npz['pos']\n",
    "    \n",
    "    ## Plot.\n",
    "    if analysis == 'stim': mask = (times > 0.4) & (times < 0.8)\n",
    "    elif analysis == 'resp': mask = (times > -0.2) & (times < 0.2)\n",
    "    plot_topomap(data[:,mask].mean(axis=-1), pos, cmap='spectral', \n",
    "                 vmin=-v, vmax=v, contours=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLPFC_5-LH Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "sns.set(style=\"white\", font_scale=1.00)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "space = 'source'\n",
    "model_name = 'revised'\n",
    "\n",
    "label = 'dlpfc_5-lh'\n",
    "freq = 'theta'\n",
    "contrast = 'DBS'\n",
    "\n",
    "baseline = (-0.5, -0.1)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Intialize figure.\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4), dpi=300)\n",
    "\n",
    "colors = ['#0571b0','#ca0020']\n",
    "labels = ['DBS OFF','DBS ON']\n",
    "\n",
    "for ax, analysis in zip(axes, ['stim','resp']):\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Load data.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Load trial information\n",
    "    info = read_csv(os.path.join(space, 'afMSIT_%s_info.csv' %space))\n",
    "\n",
    "    ## Load source data.\n",
    "    npz = np.load(os.path.join(space, 'afMSIT_%s_%s_%s_%s.npz' %(space,analysis,label,freq)))\n",
    "    data = npz['data']\n",
    "    times = npz['times']\n",
    "\n",
    "    ## Load cluster results.\n",
    "    f = os.path.join(space, 'results', '%s_%s_frequency_results.csv' %(model_name, analysis))\n",
    "    clusters = read_csv(f)\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Main plotting.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Plot lines.\n",
    "    for m, color, legend in zip([0,1],colors,labels):\n",
    "\n",
    "        ## Identify DBS on/off trials.\n",
    "        ix, = np.where(info.DBS==m)\n",
    "        \n",
    "        ## Compute average time course.\n",
    "        mu = data[ix].mean(axis=0)\n",
    "        \n",
    "        ## If stimulus-locked, baseline subtract.\n",
    "        if analysis == 'stim': mu -= mu[(times >= baseline[0])&(times <= baseline[1])].mean()\n",
    "            \n",
    "        ## Compute standard error. \n",
    "        se = data[ix].std(axis=0) / np.sqrt(len(ix))\n",
    "        \n",
    "        ## Plotting.\n",
    "        ax.plot(times, mu, linewidth=3, color=color, label=legend)\n",
    "        ax.fill_between(times, mu-se, mu+se, color=color, alpha=0.15)\n",
    "\n",
    "    ## Plot significant clusters.\n",
    "    for ix in np.where((clusters.Label==label)&(clusters.Freq==freq)&\n",
    "                       (clusters.Contrast==contrast)&(clusters.FDR<0.05))[0]:\n",
    "\n",
    "        if analysis == 'stim': y1, y2 = -1.0, 2.5\n",
    "        else: y1, y2 = -1.5, 1.5\n",
    "        tmin, tmax = clusters.loc[ix,'Tmin'], clusters.loc[ix,'Tmax']\n",
    "        ax.fill_between(np.linspace(tmin,tmax,1000), y1, y2, color='k', alpha=0.2)   \n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Add flourishes.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Universal fixes.\n",
    "    ax.set_xlabel('Time (s)', fontsize=24)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    if analysis == 'stim':\n",
    "        \n",
    "        ## Fix labels/legends.\n",
    "        ax.set_ylabel(r' aIFG $\\theta$ Power (dB)', fontsize=24)\n",
    "        ax.legend(loc=2, fontsize=16, frameon=False, borderpad=0)\n",
    "        \n",
    "        ## Fix timing.\n",
    "        xticks = np.array([0.0, 0.4, 0.9, 1.4])\n",
    "        ax.set_xticks(xticks)\n",
    "        ax.set_xticklabels(xticks - 0.4)\n",
    "        ax.set_xlim(-0.25,1.5)\n",
    "        \n",
    "        ## Add time markers.\n",
    "        for x,s in zip([0, 0.4, 1.127],['IAPS','MSIT','Resp']): \n",
    "            ax.text(x+0.02,-0.95,s,fontsize=16)\n",
    "            ax.vlines(x,y1,y2,linestyle='--',alpha=0.3)\n",
    "        \n",
    "    elif analysis == 'resp':\n",
    "        \n",
    "        ## Add time markers.\n",
    "        ax.text(0.02, y1+0.05,'Resp', fontsize=16)\n",
    "        ax.vlines(0.0,y1,y2,linestyle='--',alpha=0.3)\n",
    "            \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Save figure.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            \n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('plots/manuscript/fig3/dlpfc_5-lh.png')\n",
    "plt.savefig('plots/manuscript/fig3/dlpfc_5-lh.svg')\n",
    "plt.close('all')\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant Theta Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load data.\n",
    "f = 'source/results/revised_stim_frequency_results.csv'\n",
    "df = read_csv(f)\n",
    "\n",
    "## Limit data.\n",
    "df = df[df.FDR<0.05]\n",
    "df = df[df.Freq=='theta'].reset_index(drop=True)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,12))\n",
    "\n",
    "labels = ['racc-lh', 'dacc-lh', 'pcc-lh', 'dmpfc-lh', 'dlpfc_1-lh', 'dlpfc_2-lh', \n",
    "          'dlpfc_3-lh', 'dlpfc_4-lh', 'dlpfc_5-lh', 'dlpfc_6-lh', \n",
    "          'racc-rh', 'dacc-rh', 'pcc-rh', 'dmpfc-rh', 'dlpfc_1-rh', 'dlpfc_2-rh', \n",
    "          'dlpfc_3-rh', 'dlpfc_4-rh', 'dlpfc_5-rh', 'dlpfc_6-rh']\n",
    "\n",
    "## Add timing details.\n",
    "for x,s in zip([0, 0.4, 1.127],['IAPS','MSIT','Resp']): \n",
    "    ax.text(x+0.01,-0.6,s,fontsize=20)\n",
    "    ax.vlines(x, -1, len(labels), linewidth=2.5, linestyle='--',alpha=0.2)  \n",
    "\n",
    "conds = ['DBS','Interference']\n",
    "colors = ['#ca0020','#008837']\n",
    "\n",
    "for n, label in enumerate(labels[::-1]):\n",
    "    \n",
    "    for m, contrast in enumerate(conds):\n",
    "        \n",
    "        ## Extract clusters.\n",
    "        clusters = df.loc[(df.Contrast==contrast)&(df.Label==label),['Tmin','Tmax']]\n",
    "        if not len(clusters): continue\n",
    "        \n",
    "        ## Plot clusters.\n",
    "        y = n + m * 0.5\n",
    "        for cluster in clusters.as_matrix(): \n",
    "            ax.hlines(y+0.25, cluster.min(), cluster.max(), color=colors[m], lw=24)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Add flourishes.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Add legend.\n",
    "for label, color in zip(conds,colors): \n",
    "    ax.plot([],[],lw=10,color=color,label=label,alpha=0.7)\n",
    "ax.legend(bbox_to_anchor=(0.7,1.1), handlelength=1.25, borderaxespad=0)\n",
    "\n",
    "## Fix x-axis.\n",
    "xticks = np.array([0.0, 0.4, 0.9, 1.4])\n",
    "ax.set(xticks=xticks, xticklabels=xticks-0.4, xlim=(-0.25,1.5),xlabel='Time (s)')\n",
    "\n",
    "## Fix y-axis.\n",
    "labels = ['rACC', 'dACC', 'mCC', 'SFG', 'pMFG 1', 'pMFG 2', 'aMFG 1', 'aMFG 2', 'aIFG', 'pIFG'] * 2\n",
    "ax.set(yticks=np.arange(len(labels))+0.5, yticklabels=labels[::-1], ylim=(-0.7,len(labels)))\n",
    "\n",
    "## Add dendrograms.\n",
    "def dendrogram(ax, x, y1, y2, text):\n",
    "    \n",
    "    ## Parameters\n",
    "    lw = 2.0\n",
    "    alpha = 0.2\n",
    "    \n",
    "    ## Drawing\n",
    "    ax.annotate('', (x, y1), xycoords='axes fraction', xytext=(x,y2), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate('', (x*1.02,y1), xycoords='axes fraction', xytext=(-1e-3,y1), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate('', (x*1.02,y2), xycoords='axes fraction', xytext=(-1e-3,y2), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate(text, (0,0), xycoords='axes fraction', xytext=(x*1.4, np.mean([y1,y2])), \n",
    "                rotation=90, fontsize=30, va='center')\n",
    "\n",
    "dendrogram(ax, -0.38, 0.025, 0.51, 'Right Hemisphere')\n",
    "dendrogram(ax, -0.38, 0.515, 1, 'Left Hemisphere')\n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(left=0.35, right=0.975, top=0.925, bottom=0.075)\n",
    "plt.savefig('plots/manuscript/fig3/all_theta.png', dpi=180)\n",
    "plt.savefig('plots/manuscript/fig3/all_theta.svg', dpi=180)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters\n",
    "space = 'source'\n",
    "model_name = 'revised'\n",
    "contrast = 'DBS'\n",
    "\n",
    "## Label parameters.\n",
    "labels = ['dlpfc_5-lh', 'dlpfc_4-lh', 'pcc-lh']\n",
    "xlabels = ['aIFG', 'aMFG 2', 'mCC']\n",
    "\n",
    "## Define averaging parameters.\n",
    "baseline = (-0.5, -0.1)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Preallocate space.\n",
    "analyses = []\n",
    "freqs = []\n",
    "rois = []\n",
    "values = []\n",
    "\n",
    "for analysis in ['stim','resp']:\n",
    "        \n",
    "    for label, xlabel in zip(labels,xlabels):\n",
    "    \n",
    "        for freq, ffreq in zip(['theta','alpha','beta'],\n",
    "                               [r'$\\theta$',r'$\\alpha$',r'$\\beta$']):\n",
    "    \n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Load data.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Load trial information\n",
    "            info = read_csv(os.path.join(space, 'afMSIT_%s_info.csv' %space))\n",
    "\n",
    "            ## Load source data.\n",
    "            npz = np.load(os.path.join(space, 'afMSIT_%s_%s_%s_%s.npz' %(space,analysis,label,freq)))\n",
    "            data = npz['data']\n",
    "            times = npz['times']\n",
    "\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Compute differences.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Define mask.\n",
    "            if analysis == 'stim': tmin, tmax = 0.4, 0.8\n",
    "            elif analysis == 'resp': tmin, tmax = -0.2, 0.2\n",
    "\n",
    "            ## Compute averages within window.\n",
    "            delta = []\n",
    "            for i in range(2):\n",
    "\n",
    "                ## Identify DBS on/off trials.\n",
    "                ix, = np.where(info.DBS==i)\n",
    "\n",
    "                ## Compute average time course.\n",
    "                mu = data[ix].mean(axis=0)\n",
    "\n",
    "                ## Reduce to time of interest.\n",
    "                mu = mu[(times >= tmin)&(times <= tmax)]\n",
    "                delta.append(mu)\n",
    "\n",
    "            ## Compute difference.\n",
    "            delta = np.diff(delta, axis=0).squeeze()\n",
    "            \n",
    "            ## Append information.\n",
    "            analyses += [analysis] * len(delta)\n",
    "            freqs += [ffreq] * len(delta)\n",
    "            rois += [xlabel]* len(delta)\n",
    "            values += delta.tolist()\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Compute differences.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Conver to DataFrame.\n",
    "df = DataFrame([analyses, freqs, rois, values], index=('Analysis','Freq','ROI','Delta')).T\n",
    "\n",
    "## Plot.\n",
    "g = sns.FacetGrid(df, col='Analysis', size=6, aspect=1.5)\n",
    "g.map(sns.barplot, 'ROI', 'Delta', 'Freq', ci='sd',\n",
    "      palette=sns.color_palette(n_colors=3))\n",
    "\n",
    "## Add flourishes.\n",
    "for n, ax in enumerate(g.axes.squeeze()):\n",
    "    x1, x2 = ax.get_xlim()\n",
    "    ax.hlines(0,x1,x2)\n",
    "    ax.set(xlabel = '', title='')\n",
    "    ax.legend(loc=1, labelspacing=0, borderpad=0)\n",
    "    if not n: ax.set_ylabel('Power (ON - OFF)')\n",
    "        \n",
    "plt.savefig('plots/manuscript/fig3/barplots.png', dpi=180)\n",
    "plt.savefig('plots/manuscript/fig3/barplots.svg', dpi=180)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLPFC_5-LH Correlations/ROC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=2)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "space = 'source'\n",
    "model = 'revised'\n",
    "analysis = 'stim'\n",
    "domain = 'frequency'\n",
    "contrast = 'DBS'\n",
    "label = 'dlpfc_5-lh'\n",
    "freq = 'theta'\n",
    "fdr = 0.05\n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare clinical data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "scores = read_csv('behavior/Subject_Rating_Scales.csv', index_col=0)\n",
    "subjects = scores.index\n",
    "\n",
    "madrs = scores['MADRS_Now'] - scores['MADRS_Base']\n",
    "mania = scores['Hypomania']\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare reaction time data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "rt = read_csv('behavior/EMOTE_behav_data.csv')\n",
    "rt = rt.groupby(['DBS','subject']).origResponseTimes.mean()\n",
    "rt = rt[1] - rt[0]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare power data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "info = read_csv(os.path.join(space, 'afMSIT_%s_info.csv' %space))\n",
    "\n",
    "## Load and limit cluster results.\n",
    "results = read_csv(os.path.join(space, 'results', '%s_%s_%s_results.csv' %(model,analysis,domain)))\n",
    "results = results[results.Contrast==contrast]\n",
    "results = results[results.FDR<fdr]\n",
    "results = results[results.Label == label].reset_index(drop=True)\n",
    "\n",
    "## Load time series data.\n",
    "npz = np.load(os.path.join(space, 'afMSIT_%s_%s_%s_%s.npz' %(space, analysis, label, freq)))\n",
    "data = npz['data']\n",
    "times = npz['times']\n",
    "\n",
    "## Compute condition differences.\n",
    "delta = np.zeros(subjects.shape[0])\n",
    "mask = (times >= results.Tmin.min()) & (times <= results.Tmax.max()) # NOTE: collapsing across clusters\n",
    "\n",
    "for m, subject in enumerate(subjects):\n",
    "    i, = np.where((info['Subject']==subject)&(info[contrast]==0))\n",
    "    j, = np.where((info['Subject']==subject)&(info[contrast]==1))\n",
    "    delta[m] += (data[j][:,mask].mean(axis=0) - data[i][:,mask].mean(axis=0)).mean()\n",
    "delta = Series(delta, index=subjects)\n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Construct DataFrame.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#  \n",
    "np.random.seed(47404)\n",
    "\n",
    "## Concatenate data.\n",
    "df = DataFrame([madrs,mania,rt,delta], index=['MADRS','Hypomania','RT','Delta']).T\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "def swap_arr(x,y):\n",
    "    return y.copy(), x.copy()\n",
    "\n",
    "def simple_roc(y,x):\n",
    "    '''http://blog.revolutionanalytics.com/2016/08/roc-curves-in-two-lines-of-code.html'''\n",
    "    assert np.all(np.in1d(y, [0,1]))\n",
    "    y = (y[np.argsort(x)[::-1]]).astype(bool)\n",
    "    return np.cumsum(y, dtype=float) / y.sum(), np.cumsum(~y, dtype=float) / (~y).sum()\n",
    "\n",
    "def ROC(y,x):\n",
    "    \n",
    "    ## Compute RoC, AUC.\n",
    "    tpr, fpr = simple_roc(y,x)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ## Correct for misidentification.\n",
    "    if roc_auc < 0.5:\n",
    "        roc_auc = 1 - roc_auc\n",
    "        tpr, fpr = swap_arr(tpr, fpr)\n",
    "        \n",
    "    return tpr, fpr, roc_auc\n",
    "\n",
    "## Initialize figure.\n",
    "fig  = plt.figure(figsize=(16,8))\n",
    "\n",
    "## Define plotting variables.\n",
    "colors = np.array([['#1f77b4','#2ca02c'], ['#d62728', '#9467bd']])\n",
    "xticklabels = [['No Response', 'Remission'], ['No History', 'Converted']]\n",
    "ylabels = [r'$\\Delta$ RT (s)', r'$\\Delta$ $\\theta$-power (dB)']\n",
    "\n",
    "for n, xlabel in enumerate(['MADRS', 'Hypomania']):\n",
    "    \n",
    "    for m, ylabel in enumerate(['RT','Delta']):\n",
    "           \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Preparations.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "            \n",
    "        ## Initialize axes.\n",
    "        if not n: top, bottom = 0.95, 0.6\n",
    "        else: top, bottom = 0.4, 0.05\n",
    "        if not m: left, right = 0.05, 0.435\n",
    "        else: left, right = 0.565, 0.95\n",
    "        gs = gridspec.GridSpec(1,2)\n",
    "        gs.update(left=left, right=right, top=top, bottom=bottom, wspace=0.4)\n",
    "        \n",
    "        ## Extract variables.\n",
    "        x, y = df[[xlabel,ylabel]].dropna().as_matrix().T\n",
    "        \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Correlation Plot.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "    \n",
    "        ## Plot correlation.\n",
    "        ax = plt.subplot(gs[0])\n",
    "        sns.regplot(x, y, df, color=colors[n,m], ax=ax)\n",
    "        \n",
    "        ## Add flourishes.\n",
    "        if not n and not m: ax.set(xticks=[-40,-20,0], xlabel=r'$\\Delta$ MADRS')\n",
    "        elif not n:  ax.set(xticks=[-26,-13,0], xlabel=r'$\\Delta$ MADRS')\n",
    "        else: ax.set(xticks=[0,1], xticklabels=xticklabels[n])\n",
    "        if not m: ax.set(ylim=(-0.15, 0.10), yticks=[-0.10,0.0,0.10],\n",
    "                         ylabel=ylabels[m])\n",
    "        else: ax.set(ylim=(-0.5,2), yticks=np.linspace(-0.5,2,3),\n",
    "                     ylabel=ylabels[m])\n",
    "        ax.tick_params(axis='x', which='major', pad=15)\n",
    "    \n",
    "        ## Add text.\n",
    "        r, p = pearsonr(x,y)\n",
    "        if not m and n: \n",
    "            ax.annotate('r = %0.2f, p = %0.2f' %(r,p), xy=(0,0), xytext=(0.05,0.05),\n",
    "                              xycoords = 'axes fraction', fontsize=16)\n",
    "        else:\n",
    "            ax.annotate('r = %0.2f, p = %0.2f' %(r,p), xy=(0,0), xytext=(0.3,0.05),\n",
    "                              xycoords = 'axes fraction', fontsize=16)\n",
    "    \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### RoC plots.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "    \n",
    "        if xlabel == 'MADRS':\n",
    "            x = np.where(scores['MADRS_Now'] / scores['MADRS_Base'] > 0.5, 0, 1)\n",
    "            x = x[df[ylabel].notnull()]\n",
    "    \n",
    "        ## Initialize plot.\n",
    "        ax = plt.subplot(gs[1])\n",
    "        ax.plot(np.linspace(0,1,10),np.linspace(0,1,10),lw=1,linestyle='--',color='k')\n",
    "        \n",
    "        ## Plot true RoC.\n",
    "        tpr, fpr, roc_auc = ROC(x, y)\n",
    "        ax.plot(fpr, tpr, lw=2, color=colors[n,m])\n",
    "        \n",
    "        auc_sim = []\n",
    "        for i in range(1000):\n",
    "            \n",
    "            ## Shuffle values.\n",
    "            if i: ix = np.random.choice(np.arange(len(x)), len(x), replace=True)\n",
    "            else: ix = np.arange(len(x))\n",
    "            x_p, y_p = x[ix].copy(), y[ix].copy() \n",
    "            \n",
    "            ## Compute AUC. \n",
    "            _, _, sim = ROC(x_p, y_p)\n",
    "            auc_sim.append( sim )\n",
    "            \n",
    "        ## Plot bootstrapped CI.\n",
    "        text = 'AUC = %0.2f [%0.2f, %0.2f]' %(roc_auc, np.nanpercentile(auc_sim, 2.5),\n",
    "                                              np.nanpercentile(auc_sim, 97.5))\n",
    "        ax.annotate(text, xy=(0,0), xytext=(0.15,0.05), xycoords = 'axes fraction', \n",
    "                    fontsize=16)\n",
    "        \n",
    "        ## Add flourishes.\n",
    "        ax.set(xticks=np.linspace(0,1,3), xlim=(-0.01,1.00), xlabel='FPR', \n",
    "               yticks=np.linspace(0,1,3), ylim=(0.00,1.01), ylabel='TPR')\n",
    "    \n",
    "sns.despine()\n",
    "plt.savefig('plots/manuscript/fig4/combo_plot.png')\n",
    "plt.savefig('plots/manuscript/fig4/combo_plot.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S3: AIC Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2)\n",
    "%load_ext rpy2.ipython\n",
    "%R require(lme4)\n",
    "%matplotlib inline\n",
    "\n",
    "## Load data.\n",
    "df = read_csv('behavior/EMOTE_behav_data.csv')\n",
    "df = df[np.where(df.responseTimes,True,False)].reset_index(drop=True)\n",
    "df['DBSxInt'] = df.DBS * df.interference\n",
    "df['AROxVAL'] = df.arousal * df.valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i df -o AICs,BICs\n",
    "\n",
    "formula = 'responseTimes ~ (1|subject)'\n",
    "variables = c('interference','DBS','valence','arousal','TrialNum', 'AROxVAL')\n",
    "AICs = c()\n",
    "BICs = c()\n",
    "\n",
    "for (variable in variables){\n",
    "    formula = paste(formula, variable, sep=' + ')\n",
    "    model = glmer(formula, data=df, family=Gamma(link='inverse'))\n",
    "    AICs = c(AICs, AIC(model))\n",
    "    BICs = c(BICs, BIC(model))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build dataframe\n",
    "variables = np.array(['Interference','DBS','Valence','Arousal','Trial #',r'Arousal $\\cdot$ Valence'] * 2)\n",
    "metrics = np.concatenate([ ['AIC'] * 6, ['BIC'] * 6 ])\n",
    "fits = DataFrame(dict(Fit = np.concatenate([AICs,BICs]),\n",
    "                      Model = variables,\n",
    "                      Metric = metrics))\n",
    "fits.Fit = np.sign(fits.Fit) * np.log(np.abs(fits.Fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "sns.set(style=\"white\", font_scale=1.75)\n",
    "g = sns.pointplot(x='Model', y='Fit', hue='Metric', data=fits, \n",
    "               palette='colorblind', kind='point', ax=ax, legend=1)\n",
    "\n",
    "## Flourishes\n",
    "ax.legend_.set_title(None)\n",
    "ax.set(xlabel='', yticks=[-8.52, -8.50, -8.48])\n",
    "ax.set_xticklabels(fits.Model.unique(), ha='left', rotation=-15, fontsize='18')\n",
    "ax.set_ylabel('Model Deviance (Log Scale)')\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/manuscript/supplementary/aic.png', dpi=300)\n",
    "plt.savefig('plots/manuscript/supplementary/aic.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S2: EEfRT Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "from scipy.stats import gamma, mannwhitneyu\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define useful functions.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "def gamma_censor(arr, threshold = 0.005):\n",
    "    '''Fit gamma distribution. Set outlier to NaN.'''\n",
    "    \n",
    "    ## Estimate fit. Loc fixed to 0.\n",
    "    p = gamma.fit(arr, floc=0)\n",
    "    \n",
    "    ## Compute likelihood of value.\n",
    "    likelihood = gamma.cdf(arr, *p)\n",
    "    \n",
    "    ## Censor and return.\n",
    "    return np.where(likelihood < threshold, np.nan, \n",
    "                    np.where(likelihood > 1 - threshold, np.nan, arr))\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load data.\n",
    "df = read_csv('behavior/clean_eefrt_behavior.csv')\n",
    "\n",
    "## Remove outlier RTs.\n",
    "df.ChoiceRT = np.where(df.ChoiceRT > 0.3, df.ChoiceRT, np.nan)       # Remove RTs faster than 300 ms.\n",
    "df.ChoiceRT = df.groupby('Subject').ChoiceRT.transform(gamma_censor) # Gamma censoring.\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
    "palette = ['#0571b0','#ca0020']\n",
    "yvars = ['ChoiceRT', 'ButtonPressRate']\n",
    "ylabels = ['Response Time (s)','Button Press Rate']\n",
    "titles = ['EEfRT Choice', 'EEfRT Bar Fill']\n",
    "\n",
    "for ax, y, ylabel, title in zip(axes, yvars, ylabels, titles):\n",
    "\n",
    "    ## Compute Wilcoxon signed-rank test.\n",
    "    U, p = mannwhitneyu(df.loc[df.DBS==0, y], df.loc[df.DBS==1, y],)\n",
    "\n",
    "    ## Plot.\n",
    "    sns.barplot('DBS', y, data=df, palette=palette, ax=ax)\n",
    "    \n",
    "    ## Add Wilcoxon info.\n",
    "    _, y2 = ax.get_ylim()\n",
    "    ax.hlines(y2, 0, 1)\n",
    "    ax.vlines(0, y2 * 0.975, y2)\n",
    "    ax.vlines(1, y2 * 0.975, y2)\n",
    "    ax.text(0.5, y2*1.025, 'U = %0.1f, p = %0.3f' %(U,p), ha='center', fontsize=24)\n",
    "    ax.set(xlabel='', xticklabels=['OFF','ON'], ylim=(0, y2*1.15), \n",
    "           ylabel=ylabel, title=title)\n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, left=0.08, right=0.99, wspace=.2)\n",
    "plt.savefig('plots/manuscript/supplementary/eefrt.png', dpi=180)\n",
    "plt.savefig('plots/manuscript/supplementary/eefrt.svg', dpi=180)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S4: FCZ ERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## File parameters.\n",
    "model_name = 'revised'\n",
    "space = 'sensor'\n",
    "label = 'FCZ'\n",
    "freq = 15\n",
    "\n",
    "## Plotting parameters.\n",
    "contrasts = ['Interference','DBS']\n",
    "palettes = [ ['#7b3294','#008837'], ['#0571b0','#ca0020'] ]\n",
    "annotations = [ ['Control', 'Interference'], ['DBS OFF','DBS ON'] ]\n",
    "ylimits = {'stim':(-5,1), 'resp':(-2.5,2.5)}\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Intialize figure.\n",
    "fig, axes = plt.subplots(2,2,figsize=(12,9))\n",
    "info = read_csv(os.path.join(space, 'afMSIT_%s_info.csv' %space))\n",
    "\n",
    "for n, contrast, colors, legends in zip(range(2), contrasts, palettes, annotations):\n",
    "    \n",
    "    for m, analysis in enumerate(['stim', 'resp']):\n",
    "\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Load data.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        ## Load source data.\n",
    "        npz = np.load(os.path.join(space, 'afMSIT_%s_%s_%s_%s.npz' %(space,analysis,label,freq)))\n",
    "        data = npz['data']\n",
    "        times = npz['times']\n",
    "\n",
    "        ## Load cluster results.\n",
    "        f = os.path.join(space, 'results', '%s_%s_timedomain_results.csv' %(model_name, analysis))\n",
    "        clusters = read_csv(f)\n",
    "        \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Plotting.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        y1, y2 = ylimits[analysis]\n",
    "        \n",
    "        for i, color, legend in zip(range(2),colors,legends):\n",
    "\n",
    "            ix, = np.where(info[contrast]==i)\n",
    "            mu = data[ix].mean(axis=0)\n",
    "            se = data[ix].std(axis=0) / np.sqrt(len(ix))\n",
    "            axes[n,m].plot(times, mu, linewidth=3, color=color, label=legend)\n",
    "            axes[n,m].fill_between(times, mu-se, mu+se, color=color, alpha=0.2)\n",
    "\n",
    "        ## Plot significant clusters.\n",
    "        for ix in np.where((clusters.Label==label)&(clusters.Freq==freq)&\n",
    "                           (clusters.Contrast==contrast)&(clusters.FDR<0.05))[0]:\n",
    "            tmin, tmax = clusters.loc[ix,'Tmin'], clusters.loc[ix,'Tmax']\n",
    "            axes[n,m].fill_between(np.linspace(tmin,tmax,1e3), y1, y2, color='k', alpha=0.2)    \n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Add flourishes.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for n in range(2):\n",
    "    \n",
    "    for m in range(2):\n",
    "        \n",
    "        y1, y2 = ylimits[analysis]\n",
    "        \n",
    "        ## Stimulus-locked edits.\n",
    "        if not m:\n",
    "            \n",
    "            ## Fix axes.\n",
    "            y1, y2 = -5, 1\n",
    "            xticks = np.array([0.0, 0.4, 0.9, 1.4])\n",
    "            axes[n,m].set(xticks=xticks, xticklabels=xticks - 0.4, \n",
    "                          xlim=(-0.25,1.5), ylim=(y1,y2), \n",
    "                          ylabel = r'FCz Voltage ($\\mu$V)')\n",
    "\n",
    "            \n",
    "            ## Add markers.\n",
    "            for x,s in zip([0, 0.4, 1.127],['IAPS','MSIT','Resp']): \n",
    "                axes[n,m].text(x+0.02,y1+np.abs(y1*0.05),s,fontsize=22)\n",
    "                axes[n,m].vlines(x,y1,y2,linestyle='--',alpha=0.3)\n",
    "                \n",
    "        ## Response-locked edits.\n",
    "        else:\n",
    "            \n",
    "            ## Fix axes.\n",
    "            xticks = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n",
    "            axes[n,m].set(xticks=xticks, xlim=(-1.0, 1.0), ylim=(y1, y2))\n",
    "                        \n",
    "            ## Add markers\n",
    "            axes[n,m].text(0.02,y1+np.abs(y1*0.05),'Resp',fontsize=22)\n",
    "            axes[n,m].vlines(0.0,y1,y2,linestyle='--',alpha=0.3)\n",
    "        \n",
    "            ## Add legends above plot.\n",
    "            axes[n,m].legend(loc=1, handlelength=1.2, handletextpad=0.5, \n",
    "                             labelspacing=0.1, borderpad=0)\n",
    "        \n",
    "        ## Add y-labels.\n",
    "        if n: axes[n,m].set_xlabel('Time (s)')\n",
    "            \n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(top=0.97, left = 0.08, right = 0.98, \n",
    "                    bottom=0.1, hspace=0.35, wspace=0.1)\n",
    "plt.savefig('plots/manuscript/supplementary/fcz.png')\n",
    "plt.savefig('plots/manuscript/supplementary/fcz.svg')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters\n",
    "space = 'source'\n",
    "model_name = 'revised'\n",
    "contrast = 'DBS'\n",
    "\n",
    "## Label parameters.\n",
    "labels = ['racc-lh', 'dacc-lh', 'pcc-lh', 'dmpfc-lh', 'dlpfc_1-lh', 'dlpfc_2-lh', \n",
    "          'dlpfc_3-lh', 'dlpfc_4-lh', 'dlpfc_5-lh', 'dlpfc_6-lh', \n",
    "          'racc-rh', 'dacc-rh', 'pcc-rh', 'dmpfc-rh', 'dlpfc_1-rh', 'dlpfc_2-rh', \n",
    "          'dlpfc_3-rh', 'dlpfc_4-rh', 'dlpfc_5-rh', 'dlpfc_6-rh']\n",
    "xlabels = ['rACC', 'dACC', 'mCC', 'SFG', 'pMFG 1', 'pMFG 2',\n",
    "           'aMFG 1', 'aMFG 2', 'aIFG', 'pIFG'] * 2\n",
    "\n",
    "## Define averaging parameters.\n",
    "baseline = (-0.5, -0.1)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Preallocate space.\n",
    "analyses = []\n",
    "freqs = []\n",
    "rois = []\n",
    "legend = []\n",
    "values = []\n",
    "\n",
    "for analysis in ['stim','resp']:\n",
    "        \n",
    "    for label, xlabel in zip(labels,xlabels):\n",
    "    \n",
    "        for freq, ffreq in zip(['theta','alpha','beta'],\n",
    "                               [r'$\\theta$',r'$\\alpha$',r'$\\beta$']):\n",
    "    \n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Load data.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Load trial information\n",
    "            info = read_csv(os.path.join(space, 'afMSIT_%s_info.csv' %space))\n",
    "\n",
    "            ## Load source data.\n",
    "            npz = np.load(os.path.join(space, 'afMSIT_%s_%s_%s_%s.npz' %(space,analysis,label,freq)))\n",
    "            data = npz['data']\n",
    "            times = npz['times']\n",
    "\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Compute differences.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Define mask.\n",
    "            if analysis == 'stim': tmin, tmax = 0.4, 0.8\n",
    "            elif analysis == 'resp': tmin, tmax = -0.2, 0.2\n",
    "\n",
    "            ## Compute averages within window.\n",
    "            delta = []\n",
    "            for i in range(2):\n",
    "\n",
    "                ## Identify DBS on/off trials.\n",
    "                ix, = np.where(info.DBS==i)\n",
    "\n",
    "                ## Compute average time course.\n",
    "                mu = data[ix].mean(axis=0)\n",
    "\n",
    "                ## Reduce to time of interest.\n",
    "                mu = mu[(times >= tmin)&(times <= tmax)]\n",
    "                delta.append(mu)\n",
    "\n",
    "            ## Compute difference.\n",
    "            delta = np.diff(delta, axis=0).squeeze()\n",
    "            \n",
    "            ## Append information.\n",
    "            analyses += [analysis] * len(delta)\n",
    "            freqs += [ffreq] * len(delta)\n",
    "            rois += [xlabel] * len(delta)\n",
    "            legend += [label] * len(delta)\n",
    "            values += delta.tolist()\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plotting.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Conver to DataFrame.\n",
    "df = DataFrame([analyses, freqs, rois, legend, values], \n",
    "               index=('Analysis','Freq','ROI','Label','Delta')).T\n",
    "df['Hemi'] = [s.split('-')[-1] for s in df.Label]\n",
    "\n",
    "## Plot.\n",
    "fig, axes = plt.subplots(4,1,figsize=(15,12))\n",
    "analyses = ['stim','stim','resp','resp']\n",
    "hemis = ['lh','rh','lh','rh']\n",
    "ylabels = ['Left Hemisphere', 'Right Hemisphere', 'Left Hemisphere', 'Right Hemisphere']\n",
    "titles = ['Stimulus-Locked',False,'Response-Locked',False]\n",
    "\n",
    "for ax, analysis, hemi, ylabel, title in zip(axes, analyses, hemis, ylabels, titles):\n",
    "    \n",
    "    ## Plot.\n",
    "    ix = np.logical_and(df.Analysis==analysis,df.Hemi==hemi)\n",
    "    sns.barplot('ROI', 'Delta', 'Freq', df[ix], palette=sns.color_palette(n_colors=3), ax=ax)\n",
    "\n",
    "    ## Add flouishes.\n",
    "    ax.hlines(0,*ax.get_xlim())\n",
    "    ax.set(xlabel = '', yticks=[0,0.5,1])\n",
    "    ax.set_xticklabels(df.ROI.unique(), fontsize=20, rotation=-15)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    ax.legend(loc=1, bbox_to_anchor=(1.125,0.9), labelspacing=0, borderpad=0, \n",
    "              handletextpad=0.25)\n",
    "    ax.legend_.set_title('Power (On - Off)', prop = {'size':'x-large'})\n",
    "    if title: ax.set_title(title)\n",
    "\n",
    "## Draw asterisks.\n",
    "for ax, analysis, hemi in zip(axes, analyses, hemis):\n",
    "    \n",
    "    ## Load significant clusters.\n",
    "    info = read_csv('source/results/revised_%s_frequency_results.csv' %analysis)\n",
    "    info = info[np.logical_and(info.Contrast=='DBS', info.FDR<0.05)]\n",
    "    info = info[[True if label.endswith(hemi) else False for label in info.Label]]\n",
    "    info = info[['Label','Freq']].drop_duplicates()\n",
    "    \n",
    "    ## Iteratively draw asterisks.\n",
    "    for _, row in info.iterrows():\n",
    "        \n",
    "        y = df.loc[(df.Analysis==analysis)&(df.Label==row.Label)&\n",
    "                   (df.Freq==r'$\\%s$' %row.Freq),'Delta'].mean()\n",
    "        x1 = np.argmax(np.in1d(df.loc[df.Hemi==hemi,'Label'].unique(), row.Label))\n",
    "        x2 = np.argmax(np.in1d(['theta','alpha','beta'], row.Freq))\n",
    "        ax.annotate('*', xy=(0,0), xytext=(-0.32 + x1 + 0.28 * x2, y+0.05),\n",
    "                              xycoords='data', fontsize=24)\n",
    "        \n",
    "sns.despine()\n",
    "plt.subplots_adjust(left=0.075, right=0.9, top=0.95, bottom=0.06, hspace=0.5)\n",
    "plt.savefig('plots/manuscript/supplementary/S5.png', dpi=180)\n",
    "plt.savefig('plots/manuscript/supplementary/S5.svg', dpi=180)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S6: Out of Task Power\n",
    "####  PSD of eyes-open resting state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mne import Epochs, make_fixed_length_events, pick_channels, read_proj, set_log_level\n",
    "from mne.io import Raw\n",
    "from mne.time_frequency import psd_multitaper\n",
    "set_log_level(verbose=False)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define Parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "subjects = ['BRTU', 'CHDR', 'JADE', 'S2']\n",
    "conds = ['resting_dbsoff_eo', 'resting_dbson_eo']\n",
    "\n",
    "## Filtering parameters.\n",
    "l_freq = 0.5\n",
    "h_freq = 50\n",
    "l_trans_bandwidth = l_freq / 2.\n",
    "h_trans_bandwidth = 1.0\n",
    "filter_length = '20s'\n",
    "n_jobs = 3\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "root_dir = '../resting/raw/'\n",
    "\n",
    "PSD = []\n",
    "for subject in subjects:\n",
    "    \n",
    "    s = []\n",
    "    for cond in conds:\n",
    "        \n",
    "        ## Load data.\n",
    "        raw = Raw('%s/%s_%s_raw.fif' %(root_dir, subject, cond), preload=True)\n",
    "\n",
    "        ## Apply projection.\n",
    "        proj = '%s/%s_%s-proj.fif' %(root_dir, subject, cond)\n",
    "        if os.path.isfile(proj): raw.add_proj(read_proj(proj))\n",
    "        else: raw.set_eeg_reference()\n",
    "        raw = raw.apply_proj()\n",
    "        \n",
    "        ## Filter raw.\n",
    "        raw = raw.filter(l_freq, h_freq, filter_length=filter_length, l_trans_bandwidth=l_trans_bandwidth,\n",
    "                        h_trans_bandwidth=h_trans_bandwidth)\n",
    "        \n",
    "        ## Create epochs.\n",
    "        events = make_fixed_length_events(raw, 1, start=1, stop=61, duration=1)\n",
    "        epochs = Epochs(raw, events, tmin=-0.5, tmax=1, baseline=(-0.5,0))\n",
    "\n",
    "        \n",
    "        ## Compute PSD\n",
    "        picks = pick_channels(raw.ch_names, ['FZ'])\n",
    "        psd, freqs = psd_multitaper(epochs, fmin=l_freq, fmax=30, picks=picks)\n",
    "        s.append(psd)\n",
    "        \n",
    "    PSD.append(s)\n",
    "    \n",
    "## Merge into one array.\n",
    "PSD = np.array(PSD).squeeze().swapaxes(0,1)\n",
    "n_cond, n_subj, n_trial, n_freq = PSD.shape\n",
    "PSD = PSD.reshape(n_cond,n_subj*n_trial,n_freq)\n",
    "\n",
    "## Plot.\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "for n, color, label in zip(range(2),['#0571b0','#ca0020'],['DBS OFF','DBS ON']):\n",
    "    \n",
    "    mu = np.median(PSD[n], axis=0)\n",
    "    mu /= mu.sum()\n",
    "    \n",
    "    ax.plot(freqs, mu, lw=3, color=color, label=label)\n",
    "    \n",
    "## Flourishes.\n",
    "ax.vlines([4,8], 0, 0.15, linestyle='--', alpha=0.5)\n",
    "ax.set(xlim=(0.5,30), xticks=(0.5,10,20,30), xticklabels=(0,10,20,30), xlabel='Frequency (Hz)',\n",
    "       ylim=(0,0.12), ylabel='Normalized PSD');\n",
    "ax.legend(loc=0, borderpad=0, labelspacing=0)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/manuscript/supplementary/S6b.png')\n",
    "plt.savefig('plots/manuscript/supplementary/S6b.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "mask = np.logical_and(freqs >= 4, freqs <= 8)\n",
    "psd = PSD[...,mask].mean(axis=-1)\n",
    "psd = np.log10(psd)\n",
    "mannwhitneyu(*psd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Timecourses of all bands in FZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## File parameters.\n",
    "model_name = 'revised'\n",
    "space = 'sensor'\n",
    "label = 'FZ'\n",
    "\n",
    "baseline = (-0.5, -0.1)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load trial information.\n",
    "info = read_csv('%s/afMSIT_sensor_info.csv' %space)\n",
    "cdict = dict(DBS = ['#0571b0','#ca0020'], Interference = ['#7b3294','#008837'])\n",
    "ldict = dict(DBS = ['DBS OFF','DBS ON'], Interference = ['Control', 'Interference'])\n",
    "\n",
    "## Initialize figure.\n",
    "fig = plt.figure(figsize=(18,12))\n",
    "\n",
    "for i, analysis in enumerate(['stim','resp']):\n",
    "    \n",
    "    results = read_csv('sensor/results/revised_%s_frequency_results.csv' %analysis)\n",
    "    \n",
    "    for j, freq in enumerate(['theta','alpha','beta']):\n",
    "        \n",
    "        ## Load data.\n",
    "        npz = np.load('%s/afMSIT_%s_%s_%s_%s.npz' %(space,space,analysis,label,freq))\n",
    "        data = npz['data']\n",
    "        times = npz['times']\n",
    "        \n",
    "        for k, contrast in enumerate(['DBS', 'Interference']):\n",
    "            \n",
    "            ## Initialize canvas.\n",
    "            ax = plt.subplot2grid((4,3),(k+i*2,j))\n",
    "            \n",
    "            ## Plot power.\n",
    "            for n, color, legend in zip(range(2),cdict[contrast],ldict[contrast]):\n",
    "\n",
    "                ## Identify indices per condition of contrast.\n",
    "                ix, = np.where(info[contrast]==n)\n",
    "                \n",
    "                ## Compute mean and standard error.\n",
    "                mu = data[ix].mean(axis=0)\n",
    "                \n",
    "                ## If stimulus-locked, baseline subtract.\n",
    "                if analysis == 'stim': mu -= mu[(times >= baseline[0])&(times <= baseline[1])].mean()\n",
    "                \n",
    "                se = data[ix].std(axis=0) / np.sqrt(len(ix))\n",
    "                \n",
    "                ## Plot.\n",
    "                ax.plot(times, mu, linewidth=3, color=color, label=legend)\n",
    "                ax.fill_between(times, mu-se, mu+se, color=color, alpha=0.2)\n",
    "            \n",
    "                ## Plot significant clusters.\n",
    "                for _, row in results.loc[(results.Contrast==contrast)&(results.Label==label)&\n",
    "                                       (results.Freq==freq)&(results.FDR<0.05),\n",
    "                                       ('Tmin','Tmax')].iterrows():\n",
    "                    ax.fill_between(np.linspace(row.Tmin,row.Tmax,1e3), -10, 10, color='k', alpha=0.1)    \n",
    "            \n",
    "            \n",
    "            ## Clean-up.\n",
    "            if analysis == 'stim':\n",
    "\n",
    "                ## Fix timing.\n",
    "                ax.set(xlim=(-0.25,1.5), xticks=[0.0, 0.4, 0.9, 1.4], \n",
    "                       xticklabels=[-0.4, 0.0, 0.5, 1.0], ylim=(-1.5,2), yticks=[-1, 0, 1, 2])\n",
    "\n",
    "                ## Add time markers.\n",
    "                ax.vlines([0, 0.4, 1.127],*ax.get_ylim(),linestyle='--',alpha=0.3)\n",
    "                ax.hlines(0, *ax.get_xlim(), linestyle='--',alpha=0.3)\n",
    "                \n",
    "            elif analysis == 'resp':\n",
    "\n",
    "                ## Fix timing\n",
    "                ax.set(xlim=(-1.0,1.0), xticks=np.arange(-1,1.1,0.5), ylim=(-2.5,1.5), yticks=[-2,-1,0,1])\n",
    "                \n",
    "                ## Add time markers.\n",
    "                ax.vlines(0.0,*ax.get_ylim(),linestyle='--',alpha=0.3)\n",
    "                ax.hlines(0, *ax.get_xlim(), linestyle='--',alpha=0.3)\n",
    "                \n",
    "            ## Special cases.\n",
    "            if j: ax.set(yticklabels=[])\n",
    "            if j == 2 and not k: ax.legend(loc=7, bbox_to_anchor=(1.53,0.5), labelspacing=0, handlelength=1.5)\n",
    "            if j == 2 and k: ax.legend(loc=7, bbox_to_anchor=(1.6,0.5), labelspacing=0, handlelength=1.5)\n",
    "            if not k: ax.set(xticklabels=[])\n",
    "            if not i and not k: ax.set_title(r'$\\%s$-power' %freq, fontsize=36)\n",
    "\n",
    "## Additional annotations.\n",
    "ax.annotate('Stimulus-Locked', xy=(0,0), xytext=(0.01, 0.75), xycoords='figure fraction',\n",
    "            rotation=90, fontsize=36, va='center')\n",
    "ax.annotate('Response-Locked', xy=(0,0), xytext=(0.01, 0.25), xycoords='figure fraction',\n",
    "            rotation=90, fontsize=36, va='center')\n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(left=0.07, right=0.85, top=0.95, bottom=0.05, hspace=0.175, wspace=0.15)\n",
    "plt.savefig('plots/manuscript/supplementary/S6a.png')\n",
    "plt.savefig('plots/manuscript/supplementary/S6a.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S7: Significant Alpha/Beta clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load data.\n",
    "f = 'source/results/revised_stim_frequency_results.csv'\n",
    "df = read_csv(f)\n",
    "\n",
    "## Limit data.\n",
    "df = df[df.FDR<0.05]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Defining plotting info.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define label information.\n",
    "labels = ['racc-lh', 'dacc-lh', 'pcc-lh', 'dmpfc-lh', 'dlpfc_1-lh', 'dlpfc_2-lh', \n",
    "          'dlpfc_3-lh', 'dlpfc_4-lh', 'dlpfc_5-lh', 'dlpfc_6-lh', \n",
    "          'racc-rh', 'dacc-rh', 'pcc-rh', 'dmpfc-rh', 'dlpfc_1-rh', 'dlpfc_2-rh', \n",
    "          'dlpfc_3-rh', 'dlpfc_4-rh', 'dlpfc_5-rh', 'dlpfc_6-rh']\n",
    "rois = ['rACC', 'dACC', 'mCC', 'SFG', 'pMFG 1', 'pMFG 2',\n",
    "        'aMFG 1', 'aMFG 2', 'aIFG', 'pIFG'] * 2\n",
    "\n",
    "## Define plotting features.\n",
    "conds = ['DBS','Interference']\n",
    "colors = ['#ca0020','#008837']\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Initialize figure.\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,12),sharex=True, sharey=True)\n",
    "\n",
    "for ax, freq in zip(axes,['alpha','beta']):\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Plotting Clusters.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Reduce DataFrame to frequency of interest.\n",
    "    copy = df[df.Freq==freq].copy()\n",
    "    \n",
    "    ## Plot timings.\n",
    "    for x,s in zip([0, 0.4, 1.127],['IAPS','MSIT','Resp']): \n",
    "        ax.text(x+0.01,-0.6,s,fontsize=20)\n",
    "        ax.vlines(x, -1, len(labels), linewidth=2.5, linestyle='--',alpha=0.2)  \n",
    "\n",
    "    ## Plot clusters.\n",
    "    for n, label in enumerate(labels[::-1]):\n",
    "\n",
    "        for m, contrast in enumerate(conds):\n",
    "\n",
    "            ## Extract clusters.\n",
    "            ix = np.logical_and(copy.Contrast==contrast, copy.Label==label)\n",
    "            clusters = copy.loc[ix,['Tmin','Tmax']]\n",
    "            if not len(clusters): continue\n",
    "\n",
    "            ## Plot clusters.\n",
    "            y = n + m * 0.5\n",
    "            for cluster in clusters.as_matrix(): \n",
    "                ax.hlines(y+0.25, cluster.min(), cluster.max(), color=colors[m], lw=12)\n",
    "                \n",
    "    ## Fix x-axis.\n",
    "    xticks = np.array([0.0, 0.4, 0.9, 1.4])\n",
    "    ax.set(xticks=xticks, xticklabels=xticks-0.4, xlim=(-0.25,1.5), xlabel='Time (s)')\n",
    "                \n",
    "    ## Set title\n",
    "    ax.set_title(r'$\\%s$-Power' %freq)\n",
    "                \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Add flourishes.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Add legend.\n",
    "for label, color in zip(conds,colors): \n",
    "    axes[1].plot([],[],lw=10,color=color,label=label,alpha=0.7)\n",
    "axes[1].legend(loc=7, bbox_to_anchor=(1.5,0.5), handlelength=1.25, borderaxespad=0)\n",
    "\n",
    "## Fix y-axis.\n",
    "ax.set(yticks=np.arange(len(rois))+0.5, yticklabels=rois[::-1], ylim=(-0.7,len(rois)))\n",
    "\n",
    "## Add dendrograms.\n",
    "def dendrogram(ax, x, y1, y2, text):\n",
    "    \n",
    "    ## Parameters\n",
    "    lw = 2.0\n",
    "    alpha = 0.2\n",
    "    \n",
    "    ## Drawing\n",
    "    ax.annotate('', (x, y1), xycoords='axes fraction', xytext=(x,y2), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate('', (x*1.02,y1), xycoords='axes fraction', xytext=(-1e-3,y1), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate('', (x*1.02,y2), xycoords='axes fraction', xytext=(-1e-3,y2), \n",
    "                arrowprops=dict(arrowstyle='-', color='k',  linewidth=lw, alpha=alpha))\n",
    "    ax.annotate(text, (0,0), xycoords='axes fraction', xytext=(x*1.4, np.mean([y1,y2])), \n",
    "                rotation=90, fontsize=30, va='center')\n",
    "\n",
    "dendrogram(axes[0], -0.3, 0.025, 0.51, 'Right Hemisphere')\n",
    "dendrogram(axes[0], -0.3, 0.515, 1, 'Left Hemisphere')\n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(left=0.15, right=0.85, top=0.95, bottom=0.1, wspace=0.225)\n",
    "plt.savefig('plots/manuscript/supplementary/S7.png', dpi=180)\n",
    "plt.savefig('plots/manuscript/supplementary/S7.svg', dpi=180)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, concat, read_csv\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context('notebook', font_scale=2.5)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters\n",
    "space = 'source'\n",
    "model_name = 'revised'\n",
    "contrast = 'DBS'\n",
    "freq = 'theta'\n",
    "\n",
    "## Label parameters.\n",
    "labels = ['racc-lh', 'dacc-lh', 'pcc-lh', 'dmpfc-lh', 'dlpfc_1-lh', 'dlpfc_2-lh', \n",
    "          'dlpfc_3-lh', 'dlpfc_4-lh', 'dlpfc_5-lh', 'dlpfc_6-lh']\n",
    "xlabels = ['rACC', 'dACC', 'mCC', 'SFG', 'pMFG 1', 'pMFG 2', 'aMFG 1', 'aMFG 2', 'aIFG', 'pIFG']\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        \n",
    "## Load trial information\n",
    "info = read_csv(os.path.join(space, 'afMSIT_%s_info.csv' %space))\n",
    "n_subj, = info.Subject.unique().shape\n",
    "n_cond, = info.DBS.unique().shape\n",
    "  \n",
    "corr = []\n",
    "for analysis in ['stim','resp']:\n",
    "    \n",
    "    ## Define mask.\n",
    "    if analysis == 'stim': tmin, tmax = 0.4, 0.8\n",
    "    else: tmin, tmax = -0.2, 0.2\n",
    "    \n",
    "    df = []\n",
    "    for label, xlabel in zip(labels,xlabels):\n",
    "\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Load data.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        ## Load source data.\n",
    "        npz = np.load(os.path.join(space, 'afMSIT_%s_%s_%s_%s.npz' %(space,analysis,label,freq)))\n",
    "        data = npz['data']\n",
    "        times = npz['times']\n",
    "\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Compute differences.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        ## Preallocate space.\n",
    "        mu = np.zeros((n_subj,n_cond))\n",
    "\n",
    "        for n, subject in enumerate(info.Subject.unique()):\n",
    "\n",
    "            for m in [0,1]:\n",
    "\n",
    "                ## Locate trials.\n",
    "                ix = np.logical_and(info.Subject==subject, info.DBS==m)\n",
    "\n",
    "                ## Compute average.\n",
    "                mu[n,m] = data[ix][:,(times >= tmin)&(times <= tmax)].mean()\n",
    "\n",
    "        ## Convert to DataFrame.\n",
    "        mu = DataFrame(mu, columns=('DBS_off','DBS_on'), index=info.Subject.unique())\n",
    "\n",
    "        ## Compute DBSon - DBSoff power differential.\n",
    "        mu['DBS_diff'] = mu.DBS_on - mu.DBS_off\n",
    "\n",
    "        ## Compute DBSon - DBSoff RT differential.\n",
    "        mu['RT_off'] = info.groupby(['DBS','Subject']).RT.mean()[0]\n",
    "        mu['RT_on'] = info.groupby(['DBS','Subject']).RT.mean()[1]\n",
    "        mu['RT_diff'] = mu.RT_on - mu.RT_off\n",
    "\n",
    "        ## Store label information and label.\n",
    "        mu['Label'] = label\n",
    "        mu['ROI'] = xlabel\n",
    "        df.append(mu)\n",
    "\n",
    "    ## Concatenate DataFrames.\n",
    "    df = concat(df)\n",
    "\n",
    "    ## Compute correlations.\n",
    "    gb = df.groupby('ROI')[['DBS_diff','RT_diff']].corr().reset_index()\n",
    "    gb = gb[gb.level_1=='DBS_diff'].drop(['level_1','DBS_diff'], 1)\n",
    "    gb['Analysis'] = analysis\n",
    "    corr.append(gb)\n",
    "    \n",
    "## Concatenate.\n",
    "corr = concat(corr)\n",
    "corr.Analysis = np.where(corr.Analysis=='stim','Stimulus-locked','Response-locked')\n",
    "\n",
    "## Plot.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "sns.barplot(x='ROI', y='RT_diff', hue='Analysis', data=corr, \n",
    "            order=xlabels, ax=ax)\n",
    "ax.hlines(0,-0.5,len(xlabels)+0.5)\n",
    "ax.legend(loc=7, bbox_to_anchor=(1.3,0.5), fontsize=16, handletextpad=0.2)\n",
    "ax.set(xlabel='', ylabel=\"Pearson's $r$\", title='DBS x RT Correlation')\n",
    "ax.set_xticklabels(xlabels, fontsize=16, rotation=-30)\n",
    "\n",
    "sns.despine()\n",
    "plt.subplots_adjust(left=0.12, right=0.8, top=0.85, bottom=0.17)\n",
    "plt.savefig('plots/manuscript/supplementary/S8.png', dpi=180)\n",
    "plt.savefig('plots/manuscript/supplementary/S8.svg', dpi=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S9: Lausanne Mapping\n",
    "#### Plot Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from surfer import Brain\n",
    "from pandas import read_csv\n",
    "%matplotlib qt4\n",
    "\n",
    "## Initialize brain.\n",
    "brain = Brain('fscopy', 'split', 'inflated', views = ['lateral','medial'], \n",
    "              size = (1200,800), subjects_dir='../freesurfs')\n",
    "\n",
    "## Load mapping info.\n",
    "mapping = read_csv('../freesurfs/fscopy/label/april2016/mapping.csv')\n",
    "\n",
    "emote_label = ''\n",
    "for _, row in mapping.iterrows():\n",
    "    \n",
    "    ## Load EMOTE label.\n",
    "    if not row['EMOTE Label'] == emote_label:\n",
    "        emote_label = row['EMOTE Label']\n",
    "        brain.add_label('../freesurfs/fscopy/label/april2016/%s.label' %emote_label, \n",
    "                        hemi='lh' if emote_label.endswith('lh') else 'rh',\n",
    "                        borders = True, color = row['Color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find number of vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mne import read_label, read_source_spaces\n",
    "from pandas import read_csv\n",
    "\n",
    "## Load mapping info.\n",
    "label_dir = '../freesurfs/fscopy/label/april2016'\n",
    "mapping = read_csv('%s/mapping.csv' %label_dir)\n",
    "\n",
    "## Load source space.\n",
    "src = read_source_spaces('../freesurfs/fscopy/bem/fscopy-oct-6p-src.fif', verbose=False)\n",
    "\n",
    "## Locate labels.\n",
    "labels = [f for f in os.listdir(label_dir) if f.endswith('label')]\n",
    "\n",
    "## Iteratively identify number of labels in source space.\n",
    "mapping['Vertices'] = 0\n",
    "for label in labels:\n",
    "    \n",
    "    ## Load label.\n",
    "    label = read_label('%s/%s' %(label_dir,label))\n",
    "    \n",
    "    ## Compute number of vertices in source space.\n",
    "    n_vert = np.in1d(src[0 if label.hemi == 'lh' else 1]['vertno'], label.vertices).sum()\n",
    "    \n",
    "    ## Store in DataFrame.\n",
    "    mapping.loc[mapping['EMOTE Label']==label.name, 'Vertices'] = n_vert\n",
    "    \n",
    "mapping.to_csv('%s/mapping.csv' %label_dir, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "819px",
    "left": "0px",
    "right": "1089px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
